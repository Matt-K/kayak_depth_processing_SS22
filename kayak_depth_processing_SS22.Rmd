---
title: "extracting average depth data from sonar transects"
author: "MKAUFMAN"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

## setup
```{r message=FALSE}

library(htmlwidgets)
library(plotly)
library(rgdal)
library(data.table)
```
## set file name
```{r message=FALSE}
filename<-'Sonar_2022-08-02_12.34.00G.csv'
folderpath<-'C:/Users/kauf093/OneDrive - PNNL/Spatial Study 2022/10_Sonar/01_RawData/2022-08-02/S34R/'
filepath<-paste(folderpath,filename,sep='')

```
  
  
## import a sonar log from csv (this must be created with the python library sllib ahead of time)

```{r message=FALSE}
#enter the time between initializing the sonar log file name and the start of actual logging. should be about 30 seconds
sonartimeoffsetseconds<-30


sonarfilename=filepath
rawlog=read.csv(file = sonarfilename,sep=',') 

sonaryear=as.numeric(substr(sonarfilename,7,10))
sonarmonth=as.numeric(substr(sonarfilename,12,13))
sonarday=as.numeric(substr(sonarfilename,15,16))
sonarhour=as.numeric(substr(sonarfilename,18,19))
sonarminute=as.numeric(substr(sonarfilename,21,22))
sonarsecond=as.numeric(substr(sonarfilename,24,25))

sonarstart=substr(sonarfilename,7,25)

sonarstart<-as.POSIXct(strptime(sonarstart, "%Y-%m-%d_%H.%M.%S"))
sonarstart=sonarstart+sonartimeoffsetseconds


#set coordinate system
cord.dec = SpatialPoints(cbind(rawlog$longitude, rawlog$latitude), proj4string=CRS("+proj=longlat"))

#convert to meters (UTM zone 10 north)
cord.UTM <- spTransform(cord.dec, CRS("+init=epsg:32610"))

log=rawlog
log$UTMx=cord.UTM$coords.x1
log$UTMy=cord.UTM$coords.x2
log=log[which(log$framesize==3216),]

#average depth
superroughmeandepthm<-mean(log$water_depth_m)

#create date/time object from start time (from file name), time offset, and elapsed milliseconds
log <- log[order(log$time1),]
log$elapsec<-log$time1/1000
log$sonartime<-sonarstart+log$elapsec

```
##clean data
```{r}
#remove the top 1% of values, as these are typically spurious
log$water_depth_m[log$water_depth_m > quantile(log$water_depth_m, probs = 0.99)] <- NA 

#get minimum sonar reading
mindepth=min(log$water_depth_m)
#count min
#sum(log$water_depth_m == mindepth)
#replace all minimum entries with half of the minimum depth
log$water_depth_m[log$water_depth_m == mindepth] <- mindepth/2

#add depth offset (5 inches)
log$water_depth_m <- log$water_depth_m+0.127

#make 1-meter rounded coordinate for aggregation
log$UTMxR<-round(log$UTMx,0)
log$UTMyR<-round(log$UTMy,0)
log$group<-paste(log$UTMxR,log$UTMyR,sep=",")

spatialmean<-aggregate(water_depth_m ~ group, data = log, mean)
spatialmean$UTMx<-substr(spatialmean$group, 0, 6)
spatialmean$UTMy<-substr(spatialmean$group, 8, 14)

```

#plot spatially-aggregated data
```{r}
fig <- plot_ly(type = 'scatter', mode = 'markers',marker=list(
    color=spatialmean$water_depth_m,
    cmin = 0,
    cmax = max(spatialmean$water_depth_m),
    colorbar=list(
      title='1m averaged depth (m)'),
    colorscale='Viridis',
    reversescale=TRUE
  )) 
fig <- fig %>%
  add_trace(
    x = spatialmean$UTMx, 
    y = spatialmean$UTMy,
  hovertext = spatialmean$water_depth_m
   
  )

fig

savefilename<-paste(substr(filename,0,nchar(filename)-4),'.html',sep='')
savefilepath<-paste(folderpath,savefilename,sep='')
htmlwidgets::saveWidget(partial_bundle(fig), savefilepath)
```

##export results table
```{r message=FALSE}

outfilename<-paste(substr(filename,0,nchar(filename)-4),'_mean.csv',sep='')
outfilepath<-paste(folderpath,outfilename,sep='')
notes <- data.frame(matrix(ncol = 2, nrow = 1))

notes[1,1]<-"Sonar data cleaned (<detection set to half of detection limit), binned into 1-meter-square cells, then averaged. Average depth (m):"
notes[1,2]<-mean(spatialmean$water_depth_m)
write.table(notes, file = outfilepath, append = TRUE, quote = TRUE, sep = ",", row.names = FALSE, col.names = FALSE)

```